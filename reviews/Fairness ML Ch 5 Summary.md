Chapter 5 of the Fairness ML Book first describes real-world studies in human decision making and shows that in some of those cases, attribute flipping may not be as wholly effective as a result of other characteristics that may inform the decision (with an example being human temperament at the time of the decision being made). However, in our case, if we are simply feeding the model data that is mainly composed of words linked to sensitive attributes, this attribute flipping may be enough. The paper also touches on NLP, especially in tweets, and how a lack of training data can make tweets written a certain way, such as in AAVE, can have higher false negative rates. Other than that, there is not much we can take from this chapter in particular, aside from its discussion on NLP and different types of discrimination.
