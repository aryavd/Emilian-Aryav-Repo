# Literature Review
Refer to the template for review guidelines <https://github.com/aryavd/Emilian-Aryav-Repo/blob/main/template.md>.

## Must read 
* Beyond Accuracy: Behavioral Testing of NLP models with CheckList (https://arxiv.org/abs/2005.04118)
* Gender Bias in Contextualized Word Embeddings (https://arxiv.org/abs/1904.03310)

## Split reads between Aryav and Emilian
* Fairness in Machine Learning book (https://fairmlbook.org/index.html) 
** Chapter 2 on classification 
** Chapter 5 on testing discrimination in practice

* A Survey on Bias and Fairness in Machine Learning (https://arxiv.org/abs/1908.09635)

* A framework for understanding Sources of Harm throughout the Machine Learning Life Cycle (https://arxiv.org/pdf/1901.10002.pdf)

* What's in the Box? A Preliminary Analysis of Undesirable Content in the Common Crawl Corpus (https://arxiv.org/abs/2105.02732) 

* In Marianne Bertrand and Sendhil Mullainathan’s audit study, “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination,” fictitious résumés with randomized raced names are sent out to employers looking to hire. Since the résumés are identical except for the differently raced names of the applicants, the difference in callback rates between résumés with names raced white (the Emilys and Gregs) and résumés with names raced black (the Lakishas and Jamals) is interpreted as being due to the decision-makers’ perception of race.

* The meaning and measurement of bias: lessons from natural language processing (https://dl.acm.org/doi/abs/10.1145/3351095.3375671)

* A survey of data augmentation approaches for NLP (https://arxiv.org/abs/2105.03075) 

* Towards Understanding and Mitigating Social Biases in Language Models (https://arxiv.org/abs/2106.13219) 
