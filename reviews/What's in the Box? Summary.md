The authors in the paper seek to identify the undesirable content in the Common Crawl Corpus, such as hate speech or sexually explicit content, and point out the risks to using such a dataset to train oneâ€™s model. The method they used in the paper involves using DEMLIT (trained on social media), Hate Sonar (which uses classic NLP techniques), and an n-gram based approach with n-grams from Hate Base to detect hate speech. They also used an n-gram based approach to detect sexually explicit content. They also tested filtering by perplexity, commonly used to clean datasets like Wikipedia. While it detected some sexually explicit content, much hate speech was left undetected, posing potential harm. The varying results of each revealed how there does not exist one general data-filtering approach. Analyzing Common Crawl also requires considerable computational resources, which is another obstacle in cleaning it. However, training models on datasets containing the hate speech like that found in Common Crawl can lead to a plethora of issues in the model later on, which means that extensively analyzing the corpus used to train a given model is prudent. The approaches mentioned are not particularly relevant to us, as the model we are testing is already trained, presumably on some dataset, meaning we cannot go back and clean it once more. 
